{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89425b1a",
   "metadata": {},
   "source": [
    "`dropna()` - Метод для удаления строк и столбцов, который позволяет удалять пропуски с тонким подходом к настройке. \n",
    "\n",
    "**Основные параметры метода:**\n",
    "\n",
    "- `axis` — ось, по которой производится удаление (по умолчанию 0 — строки).\n",
    "\n",
    "- `how` — как производится удаление строк (any — если хотя бы в одном из столбцов есть пропуск, стоит по умолчанию; all — если во всех столбцах есть пропуски). \n",
    "\n",
    "- `thresh` — порог удаления. Определяет минимальное число непустых значений в строке/столбце, при котором она/он сохраняется. Например, если мы установим thresh в значение 2, то мы удалим строки, где число пропусков больше чем `n-2`, где  `n` — число признаков (если `axis=0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e5e5b",
   "metadata": {},
   "source": [
    "`hist()` - Метод *Pandas* для вывода на экран распределения признаков с пропусками "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc2565",
   "metadata": {},
   "source": [
    "`fillna()` - Метод для заполнения пустых значений\n",
    "\n",
    "Главный параметр метода — `value` (значение, на которое происходит заполнение данных в столбце). Если метод вызывается от имени всего *DataFrame*, то в качестве `value` можно использовать **словарь**, где **ключи — названия столбцов таблицы, а значения словаря — заполняющие константы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ce4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция поиска выбросов по методу Тьюки\n",
    "#def outliers_iqr(data, feature):\n",
    "    #x = data[feature]\n",
    "    #quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),\n",
    "    #iqr = quartile_3 - quartile_1\n",
    "    #lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    #upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    #outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    #cleaned = data[(x >= lower_bound) & (x <= upper_bound)]\n",
    "    #return outliers, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7920661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для поиска выбросов методом z-отклонений\n",
    "#def outliers_z_score(data, feature, log_scale=False):\n",
    "    # Если аргумент = True, логарифмируем признак\n",
    "  #  if log_scale:\n",
    " #       x = np.log(data[feature]+1)\n",
    " #   # Иначе - оставляем его в исходном виде\n",
    " #   else:\n",
    " #       x = data[feature]\n",
    " #   mu = x.mean()\n",
    "  #  sigma = x.std()\n",
    "\n",
    " #   lower_bound = mu - 3 * sigma\n",
    " #   upper_bound = mu + 3 * sigma\n",
    " #   outliers = data[(x < lower_bound) | (x > upper_bound)] # | - Это побитовое \"или\"\n",
    "  #  cleaned = data[(x >= lower_bound) & (x <= upper_bound)]\n",
    "  #  return outliers, cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2548e8",
   "metadata": {},
   "source": [
    "`skew()` - метод для вычисления численного показателя асимметрии \n",
    "\n",
    "`print(log_mkad_km.skew())`\n",
    "\n",
    "Асимметрия распределения называется правосторонней, если она \n",
    "положительная:\n",
    "As > 0;\n",
    "\n",
    "Асимметрия распределения называется левосторонней, если она \n",
    "отрицательная:\n",
    "As < 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f4a84",
   "metadata": {},
   "source": [
    "`duplicated()` - Метод для отслеживания дубликатов. Возвращает булеву маску для фильтрации: если признаки совпадают - True, для остальных - False\n",
    "\n",
    "Параметр `subset` - список признаков, по которым проводится поиск дубликатов (по умолчанию - все столбцы в *DataFrame* и ищутся **полные дубликаты**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a23fe0",
   "metadata": {},
   "source": [
    "`drop_duplicates()` - Метод для удаления повторяющихся записей из таблицы\n",
    "`sber_dedupped = sber_data.drop_duplicates(subset=dupl_columns)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204a7ee",
   "metadata": {},
   "source": [
    "Разберем **алгоритм** поиска неинформативных признаков:\n",
    "\n",
    "→ Создаём пустой список *low_information_cols*, куда будем добавлять названия признаков, которые мы посчитаем неинформативными.\n",
    "\n",
    "→ В цикле пройдёмся по всем именам столбцов в таблице и для каждого будем совершать следующие действия:\n",
    "\n",
    "- рассчитаем `top_freq` — наибольшую относительную частоту с помощью метода `value_counts()` с параметром `normalize=True`. Метод вернёт **долю от общих данных, которую занимает каждое уникальное значение в признаке**.\n",
    "\n",
    "\n",
    "- рассчитаем `nunique_ratio` — **отношение числа уникальных значений** в столбце **к размеру всего столбца**. **Число уникальных значений** в столбце получим с помощью метода `nunique()`, а **размер** признака — с помощью метода `count()`. \n",
    "\n",
    "- **сравним** каждое из полученных чисел **с пороговым значением** (у нас это 0.95) и добавим в **список неинформативных признаков, если условие истинно**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c58157",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
